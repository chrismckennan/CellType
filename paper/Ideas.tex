\documentclass{article}

\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage[letterpaper, portrait, margin=1.0in]{geometry}
\graphicspath{ {~/Desktop/Uchicago/STAT_347/HW/HW2/QuestionA3} }
\usepackage{mathrsfs}
\usepackage{breqn}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{txfonts}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\usepackage{units}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{setspace}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the 
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

\begin{document}

Suppose we have methylation data for $p$ CpG sites on the logit scale (i.e. logit(beta value)) for two sets of individuals, $Y_1, Y_2$, where $Y_i \in \mathbb{R}^{p \times n_i}$ and $n_i$ the number of individuals in each group. Let $X_i \in \mathbb{R}^{d \times n_i}$ be the covariate matrix for $d$ covariates of interest (i.e. sex, asthma status, etc.) and $C_i \in [0,1]^{K \times n_i}$ be the cell type matrix for $K+1$ cell types ($K+1$ since $X_i$ has an intercept). If $c_s^{(i)}$ is the $s^{\text{th}}$ column of $C_i$, then $\bm{1}^T c_s^{(i)} < 1$. The data are then modeled linearly as
\[
Y_i = B_{p \times d} X_i + L_{p \times K} C_i + E_i, \text{ } E_i \sim MN_{P \times n_i}\left( 0, \Sigma_{p \times p}, I_{n_i} \right)
\]
In our set up, we observed $X_1, X_2$ and $C_1$ but NOT $C_2$. For now, we assume that the columns of $C_i$ follow a dirichlet distribution with
\[
C_i \mid X_i, \Omega \sim \underbrace{\left( \text{Dir}\left( \alpha\Omega x_{1_1} \right)^T, \ldots, \text{Dir}\left( \alpha\Omega x_{1_{n_i}} \right)^T \right)}_{\text{$n_i$ independent Dirichlet distributions}}
\]
where $\Omega \in \mathbb{R}^{K \times d}$ and $\alpha > 0$ is a concentration parameter. Note that
\[
E\left( C_i \mid X_i, \Omega \right) = \Omega X_i^T
\]
\[
\text{Var}\left( c_s^{(i)} \mid X_i, \Omega \right) = \frac{1}{\alpha + 1}\left( \text{diag}\left( \Omega x_{i_s} \right) - \Omega x_{i_s} \left( \Omega x_{i_s} \right)^T \right)
\]
and
\[
E\left( Y_1 \mid X_1, X_2, C_1 \right) = BX_1 + LC_1
\]
\[
E\left(  Y_2 \mid X_1, X_2, C_1 \right) = BX_2 + LE\left( \Omega \mid X_1, X_2, C_1 \right) X_2
\]

\subsection{Estimating $\Omega$}
Let $l\left( \Omega, \alpha \mid C_1 \right) = \log p\left( C_1 \mid \Omega, \alpha \right)$ and let $\hat{\Omega}, \hat{\alpha} = \hat{\Omega}\left( C_1 \right), \hat{\alpha}\left( C_1 \right)$ be the MLE. In order to estimate $B$ and $L$ I condition on $C_1$, which meaning there is no randomness in $\hat{\Omega}, \hat{\alpha}$ in the usual frequentist setting. In order to introduce uncertainty back into the estimates $\hat{\Omega}, \hat{\alpha}$, I assume there is a prior $p\left( \Omega, \alpha \right)$ with compact support on $\Omega, \alpha$. If we define $h = \left( \text{vec}\left( \Omega \right), \alpha \right)$, we have
\[
\log	p\left( \Omega, \alpha \mid C_1 \right) = Const + \underbrace{l\left( \Omega, \alpha \mid C_1 \right)}_{O_P\left(  n_1^{1/2}\right)} + \underbrace{\log p\left( h \right)}_{O_p(1)} = Const + l\left( \hat{h} \mid C_1 \right) - \underbrace{\frac{1}{2}\left( h - \hat{h}\right)^T H\left( \hat{h} \right) \left( h - \hat{h} \right)}_{\text{Kernel of a $N\left( \hat{h}, H\left( \hat{h} \right)^{-1} \right)$}} + o_P\left( \norm{h - \hat{h}}^2 \right) + \log p\left( h \right)
\]
where $H = -\nabla^2_{hh}l \mid_{\hat{h}} \approx \mathcal{I}\left( \hat{h} \right)$, the Fisher information at $\hat{h}$. Since $\frac{1}{2}\left( h - \hat{h}\right)^T H\left( \hat{h} \right) \left( h - \hat{h} \right)$ dominates the above expression for large $n_1$, we may approximate $p\left( h \mid C_1 \right)$ with a normal distribution:
\[
p\left( h \mid C_1 \right) \approx N\left( \hat{h}, \mathcal{I}\left( \hat{h} \right)^{-1} \right).
\]
This is exactly the Bayesian central limit theorem.

For our asymptotic results, we only need the asymptotic first and second moments of $p\left( h \mid C_1 \right)$ (and possibly the assumption that higher moments exist, which is why I assume the prior for $h$ has compact support), along with $n_1 = O\left( n_2 \right)$. The intuition for this is that the variance matrix for the second set of individuals will have $n_2^2$ entries, where the off-diagonal elements all are on the order $\frac{1}{n_1}$ (from the variance of $\Omega, \alpha \mid C_1$). In order to ensure that the maximum eigenvalue of this matrix doesn't explode as $n_2 \to \infty$, we require $n_1 = O\left( n_2 \right)$. When this is the case, I am pretty sure I can prove consistency of the the quasi-likelihood estimator.

\subsection{Quasi-Likelihood Estimator}
Since the Normal + Dirichlet is a difficult likelihood to work with, I use a quasi-likelihood estimator. For each CpG site $g = 1, \ldots, p$, let $y_{i_g}$ be the $g^{\text{th}}$ row of $Y_1$, $\ell_g$ the $g^{\text{th}}$ column of $L$ and $\beta_g$ the $g^{\text{th}}$ column of $B$. Let $\tilde{\beta}_g = \left( \begin{matrix}
\beta_g\\
\ell_g
\end{matrix} \right)$. The model for these individual sites is
\[
y_{1_g} = X_1^T \beta_g + C_1^T \ell_g + \epsilon_{1_g}, \text{ } \epsilon_{1_g} \sim N\left( 0, \sigma_g^2 \right)
\]
\[
y_{2_g} = X_2^T \beta_g + C_2^T \ell_g + \epsilon_{2_g}, \text{ } \epsilon_{2_g} \sim N\left( 0, \sigma_g^2 \right)
\]
where $\epsilon_{i_g}$ is independent of $C_2$. The \textbf{means} of the random variables are
\[
\mu_{1_g} = \mu_{1_g}\left( \beta_g, \ell_g \right) = E\left( y_{1_g} \mid X_1, X_2, C_1 \right) = X_1^T \beta_g + C_1^T \ell_g
\]
\[
\mu_{2_g} = \mu_{2_g}\left( \beta_g, \ell_g \right) = E\left( y_{2_g} \mid X_1, X_2, C_1 \right) = X_2^T \beta_g + \underbrace{E\left( C_2 \mid X_2, C_1 \right)^T}_{= X_2^T\left( \hat{\Omega}^T + O\left( \frac{1}{\sqrt{n_1}} \right) \right)} \ell_g.
\]
The \textbf{variances} are
\[
\text{Var}\left( y_{1_g} \mid X_1, X_2, C_1 \right) = \sigma_g^2 I_{n_1}
\]
\[
\text{Var}\left( y_{2_g} \mid X_1, X_2, C_1 \right) = \text{Var}\left( C_2^T \ell_g \mid X_2, X_1, C_1 \right) + \sigma_g^2 I_{n_2} = G\left( \ell_g \right).
\]
Let $c_s$ and $c_t$ be the $s$ and $t^{\text{th}}$ columns of $C_2$, respectively. Define
\[
R_s = \frac{1}{\alpha + 1}\left( \text{diag}\left( \Omega x_{2_s} \right) - \Omega x_{2_s} \left( \Omega x_{2_s} \right)^T \right) \text{ and } V_s = E_{\Omega, \alpha \mid C_1, X_1, X_2}R_s = O\left( 1 \right).
\]
\[
S_{ss} = \underbrace{\text{Var}_{h\mid C_1, X_1, X_2}\left( E\left( c_s \mid C_1, X_1, X_2, \Omega \right) \right)}_{\text{Variance taken over $p\left( h \mid C_1, X_1, X_2 \right)$}} = O\left( \frac{1}{n_1} \right)
\]
\[
S_{st} = \text{Var}_{h\mid C_1, X_1, X_2} \left( E\left( c_s \mid C_1, X_1, X_2, \Omega \right), E\left( c_t \mid C_1, X_1, X_2, \Omega \right) \right) = O\left( \frac{1}{n_1} \right)
\]
Finally, we can get an analytic expression for $G(\ell_g)$ by noting that
\[
\text{Var}\left( C_2^T \ell_g \mid X_2, X_1, C_1 \right) = \left( \begin{matrix}
\ell_g^T \left( V_1 + S_{11} \right) \ell_g & \cdots & \ell_g^T S_{n_2 1} \ell_g\\
\vdots & \ddots & \vdots\\
\ell_g^T S_{1 n_2} \ell_g & \cdots & \ell_g^T \left( V_{n_2} + S_{n_2n_2} \right) \ell_g
\end{matrix} \right) \in \mathbb{R}^{n_2 \times n_2}
\]
Next, we define
\[
U = \left[ \begin{matrix}
X_1 & X_2\\
C_1 & E\left( C_2 \mid X_1, X_2, C_1 \right)
\end{matrix} \right] \left( \begin{matrix}
\frac{1}{\sigma_g^2} \left( y_{1_g} - \mu_{1_g} \right)\\
G\left( \ell_g \right)^{-1}\left( y_{2_g} - \mu_{2_g} \right)
\end{matrix} \right)
\]
and
\[
T = -E\left( \frac{dU}{d\tilde{\beta}} \mid X_1, X_2, C_1 \right) = \text{Var}\left( U \mid X_1, X_2, C_1 \right) = \left[ \begin{matrix}
X_1 & X_2\\
C_1 & E\left( C_2 \mid X_1, X_2, C_1 \right)
\end{matrix} \right] \left( \begin{matrix}
\frac{1}{\sigma_g^2} I_{n_1} & 0\\
0 & G\left( \ell_g \right)^{-1}
\end{matrix} \right) \left[ \begin{matrix}
X_1 & X_2\\
C_1 & E\left( C_2 \mid X_1, X_2, C_1 \right)
\end{matrix} \right]^T = 
\]
\[
\left[ \begin{matrix}
X_1 & X_2\\
C_1 & \hat{\Omega} X_2
\end{matrix} \right] \underbrace{\left( \begin{matrix}
\frac{1}{\sigma_g^2} I_{n_1} & 0\\
0 & G\left( \ell_g \right)^{-1}
\end{matrix} \right)}_{\lambda_{\min} > \delta, \lambda_{\max} < Const} \left[ \begin{matrix}
X_1 & X_2\\
C_1 & \hat{\Omega} X_2
\end{matrix} \right]^T \left( 1 + O_P\left( \frac{1}{\sqrt{n_1}} \right) + O_P\left( \frac{1}{n_1} \right) \right) \approx \left[ \begin{matrix}
X_1 & X_2\\
C_1 & \hat{\Omega} X_2
\end{matrix} \right] \underbrace{\left( \begin{matrix}
\frac{1}{\sigma_g^2} I_{n_1} & 0\\
0 & G\left( \ell_g \right)^{-1}
\end{matrix} \right)}_{\lambda_{\min} > \delta, \lambda_{\max} < Const} \left[ \begin{matrix}
X_1 & X_2\\
C_1 & \hat{\Omega} X_2
\end{matrix} \right]^T.
\]
The \textbf{Newton Updates} are then
\[
\hat{\tilde{\beta}}_{k+1} = \hat{\tilde{\beta}}_{k} + T_{k}^{-1} U_{k}.
\]

\subsection{What I need to Prove}
I still need prove that the estimator $\hat{\tilde{\beta}} \stackrel{P}{\to} \tilde{\beta}$ when $n_1 = O\left( n_2 \right)$ and under what conditions we have asymptotic normality. Once I prove these, I already have a proof showing that if consistency and asymptotic normality hold when $\sigma_g^2$ is know, it also holds when is use the OLS plugin estimator for $\sigma_g^2$ based on the $n_1$ individuals.

\subsection{Other Possible Models}
In the above model I assumed that the methylation response $Y$ are M-values (i.e. $\text{logit}\left( \frac{\#\text{methylated$ + \alpha$}}{\#\text{methylated} + \#\text{unmethylated$ + \alpha$}} \right)$, $\alpha$ recommended by Illumina). The data we collect are actually count data, so a more appropriate model for the number of methylation events is binomial, i.e. if $y_{ig}$ is the number of observed methylated residues for site $g$ and $n_{ig}$ the total number of times we observe site $g$ for individual $i$,
\[
y_{ig} \sim \text{Bin}\left( n_{ig}, \pi_{ig} \right), \text{ } \pi_{ig} = f\left( \text{covariates for person $i$}, \tilde{\beta}_g \right)
\]
We can use the quasi-likelihood method above with a modification to the variance, assuming a logit link function. That is, if $V = V\left( \tilde{\beta}_g \right) = \left( \begin{matrix}
\sigma_g^2 I_{n_1} & 0\\
0 & G\left( \ell_g \right)
\end{matrix} \right)$, the new variance we would use would be
\[
V_{\text{Bin}} = \Gamma^{1/2} V \Gamma^{1/2}
\]
where $\Gamma = \text{diag}\left( \text{var}\left( \mu_1 \right), \ldots, \text{var}\left( \mu_{n_1 + n_2} \right) \right)$. Note that for $n_2 = 0$, this is just the dispersed binomial variance. This type of variance modification was used in McPeek, 2016 to correct for population specific effects in binary response data.

The only benefit to using M-values that we can better correct batch effects present in the data.

\subsection{Review of Current Methods}
To my knowledge there are three current methods to correct for cell type in methylation experiments, 2 by Houseman and 1 by Zhou.
	\begin{enumerate}
	\item \textbf{Houseman, 2012}: Houseman uses a training set consisting of methylation measured in cell types sorted by flow cytometry. The user can then feed in their methylation data matrix (on the beta scale) and get back the predicted cell types for each individuals. The problems with this method are:
		\begin{enumerate}
		\item Predicted cell type depends on population. Michelle compared her measured cell proportions with Houseman's predicted values and found that the flow cytometry data was very different that Houseman's predictions.
		\item Houseman does not provide any sort of uncertainty in the prediction, only a point estimate. This is important in assessing the uncertainty in our parameter estimates.
		\item Their model does not use covariates as information in deconvolving cell type. If two people have similar covariates, then they should also have similar cell types.
		\end{enumerate}
		
		\item \textbf{Houseman, 2014}: Houseman uses an unsupervised method to estimating regression coefficients in the presence of unmeasured cell type confounders. The shortcomings of this method are:
			\begin{enumerate}
			\item One is forced to make restrictive assumptions about the sparsity of $B$ and $L \Omega$. In an independent paper, Hastie 2016 shows that in order to get consistent estimators of $B$ in the unsupervised regime, one needs to make the assumption that the sparsity of $B$ INCREASES as the sparsity of $L$ INCREASES. That is, if the unobserved cell type does not explain a large portion of the variability in methylation (which we have seen happen, e.g. Michelles Hutterite data), then one has no hope of estimating $B$. In fact, whenever cell type DOES NOT depend on your covariates you drastically reduce your power to do inference on $B$ when you do not observe cell type.
			\item Even when $L \Omega$ is dense and $B$ is sparse, Houseman uses a poor estimator for $\hat{B}$. The asymptotic properties of his estimator are not known and it is unrealistic to get p-values for individual sites. The best we can do is get site-specific confidence intervals. We can actually improve upon this method by using a different estimator.
			\end{enumerate}
			
		\item \textbf{Zhou, 2014}: Zhou uses a linear regression treating methylation as the covariate and disease status as the response. He first forms that individual relatedness matrix $\Phi$ using the centered methylation matrix as a proxy for individual relatedness. He then iteratively adds principle components of $\Phi$ until only a small fraction of sites are significantly correlated with the phenotype. The problems here are:
			\begin{enumerate}
			\item The method is very adhoc and the statistical properties are not very well understood. 
			\item You can only look at one covariate at a time. You cannot test the hypothesis that methylation is uncorrelated with $\geq 2$ covariates at once.
			\item You lose power when performing OLS with binary response (in comparison to a GLM).
			\end{enumerate}
			
	The criticism of all of the above methods is one has no idea if the assumptions you are making on the contribution of the effect due to cell type are correct. 
	\end{enumerate}
I think the method I describe above is important for those performing large DNA methylation experiments when experimenters are unsure how methylation changes across cell type and how cell type varies across covariates. Michelle has Hutterite/Amish data at both extremes:
\begin{enumerate}
\item 30 Hutterite children ages 7-14 where cell type appears to be INDEPENDENT of the primary covariates (age, asthma, sex). If Houseman or Zhou were used here, we would incorrectly remove the majority of the effect.
\item Hutterite and Amish individuals whose cell type differs due to community, but no other covariates. No unsupervised model would be able to account for this type of data structure.
\end{enumerate}


\end{document}